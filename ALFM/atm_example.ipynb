{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from atm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/b.kabongo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/b.kabongo/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    n_users = None\n",
    "    n_items = None\n",
    "    n_topics = None\n",
    "    n_aspects = None\n",
    "    vocabulary_size = 10_000\n",
    "    gibbs_sampling_iterations = 1000\n",
    "    train_size = 0.8\n",
    "    seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(Config.seed)\n",
    "np.random.seed(Config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "        \n",
    "data_df = pd.read_csv(\"../../aspects_datasets/Beer/data.csv\")\n",
    "user_vocab = {user_id: i for i, user_id in enumerate(data_df[\"user_id\"].unique())}\n",
    "item_vocab = {item_id: i for i, item_id in enumerate(data_df[\"item_id\"].unique())}\n",
    "config.n_users = len(user_vocab)\n",
    "config.n_items = len(item_vocab)\n",
    "config.n_aspects = 4\n",
    "config.n_topics = 10\n",
    "\n",
    "data_df[\"user_id\"] = data_df[\"user_id\"].map(user_vocab)\n",
    "data_df[\"item_id\"] = data_df[\"item_id\"].map(item_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data: 100%|\u001b[36m██████████\u001b[0m| 231199/231199 [01:34<00:00, 2456.36it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = data_df.sample(frac=config.train_size, random_state=config.seed)\n",
    "data, vocabulary = process_data(config, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: [(587, 898, [['spectacular', 'murki', 'golden', 'bodi', 'top', 'larg', 'sticki', 'rocki', 'white', 'head', 'last', 'forev', 'build', 'kind', 'funni', 'shape', 'pretti', 'phenol', 'aroma', 'certain', 'clovey', 'also', 'medicin', 'ester', 'come', 'well', 'shape', 'honey', 'melon', 'pure', 'banana', 'eventu', 'close', 'earthi', 'mildest', 'cinnamon', 'note', 'appear', 'alreadi', 'quit', 'origin', 'fascin', 'featur', 'mouthfeel', 'dri', 'weizen', 'first', 'also', 'enorm', 'full', 'bodi', 'immedi', 'expand', 'thick', 'chewi', 'meringu', 'foam', 'mouth', 'uniqu', 'textur', 'full', 'wheati', 'breadi', 'perhap', 'liveliest', 'tastiest', 'origin', 'weizen', 'mani', 'way', 'get', 'respect', 'despit', 'unclean']]), (7963, 61, [['bottl', 'pour', 'clear', 'rosi', 'dark', 'brown', 'massiv', 'light', 'tan', 'head', 'sweet', 'milki', 'nose', 'nutti', 'chocol', 'charact', 'sweet', 'nutti', 'malt', 'flavor', 'like', 'pumpernickel', 'bread', 'mix', 'chocol', 'pleasant', 'smooth', 'sweet', 'much', 'hop', 'presenc', 'mayb', 'herbal', 'note', 'finish', 'smooth', 'creami', 'decent', 'amount', 'heft', 'havent', 'much', 'abita', 'know', 'get', 'kill', 'site', 'id', 'feel', 'fine', 'order', 'bar']]), (298, 3857, [['bottl', 'graini', 'light', 'toast', 'malt', 'aroma', 'detect', 'hop', 'note', 'sherri', 'clear', 'reddish', 'black', 'far', 'opaqu', 'tan', 'foam', 'hold', 'littl', 'miner', 'wateri', 'toast', 'malt', 'bread', 'crust', 'flavour', 'dunkl', 'varieti', 'sweet', 'dunkl', 'light', 'bodi', 'moder', 'carbon', 'nutti', 'finish', 'nice', 'session', 'beer']]), (436, 859, [['raven', 'pig', 'rbwg', '2010', 'courtesi', 'jcwattsrugg', 'nice', 'pretti', 'red', 'small', 'white', 'head', 'aroma', 'reek', 'oak', 'fruit', 'hint', 'alcohol', 'flavor', 'mild', 'cherri', 'malt', 'signific', 'alcohol', 'burn']]), (386, 1072, [['roasti', 'dri', 'nice', 'touch', 'sweet', 'middl', 'dri', 'finish', 'bodi', 'smooth', 'thin']])]\n"
     ]
    }
   ],
   "source": [
    "print(\"Data:\", data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['head', 'aroma', 'sweet', 'light', 'flavor', 'malt', 'bottle', 'beer', 'white', 'finish', 'nice', 'hops', 'taste', 'dark', 'caramel', 'good', 'medium', 'pours', 'brown', 'body', 'bitter', 'color', 'bit', 'like', 'notes', 'chocolate', 'amber', 'malty', 'little', 'nose', 'dry', 'hop', 'carbonation', 'well', 'citrus', 'clear', 'orange', 'malts', 'thin', 'bitterness', 'fruity', 'one', 'golden', 'slightly', 'roasted', 'alcohol', 'coffee', 'small', 'fruit', 'hoppy', 'creamy', 'smooth', 'palate', 'quite', 'much', 'black', 'lacing', 'flavour', 'really', 'mouthfeel', 'hazy', 'sweetness', 'bodied', 'mild', 'tan', 'great', 'yellow', 'pretty', 'slight', 'full', 'yeast', 'pale', 'flavors', 'ale', 'decent', 'big', 'strong', 'floral', 'poured', 'thanks', 'pour', 'thick', 'touch', 'deep', 'spicy', 'brew', 'hint', 'overall', 'red', 'colour', 'almost', 'lightly', 'vanilla', 'wheat', 'balanced', 'lots', 'sour', 'copper', 'tap', 'bad']\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary:\", list(vocabulary.keys())[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gibbs Sampling:  36%|\u001b[36m███▋      \u001b[0m| 364/1000 [52:10<1:31:49,  8.66s/it]"
     ]
    }
   ],
   "source": [
    "Beta_w = np.ones(config.vocabulary_size)  \n",
    "Gamma_u = np.ones(config.n_aspects)\n",
    "Gamma_i = np.ones(config.n_aspects)\n",
    "Alpha_u = np.ones(config.n_topics)\n",
    "Alpha_i = np.ones(config.n_topics)\n",
    "eta = (1, 1)\n",
    "\n",
    "params = gibbs_sampling_atm(config, data, vocabulary, Beta_w, Gamma_u, Gamma_i, Alpha_u, Alpha_i, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Phi', 'Lambda_u', 'Lambda_i', 'Theta_u', 'Psi_i', 'Pi_u'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(params, open(\"../../ALFM/Beer/params.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
